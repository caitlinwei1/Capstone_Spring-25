{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data: 502 Server Error: Bad Gateway for url: https://datasets-server.huggingface.co/rows?dataset=nyu-dice-lab%2Fwavepulse-radio-raw-transcripts&config=default&split=train&offset=105276740&length=100\n",
      "Fetched 100 rows starting at offset 560049537\n",
      "Fetched 100 rows starting at offset 344609279\n",
      "Fetched 100 rows starting at offset 56990448\n",
      "Fetched 100 rows starting at offset 82007761\n",
      "Fetched 100 rows starting at offset 432663039\n",
      "Fetched 100 rows starting at offset 214045419\n",
      "Fetched 100 rows starting at offset 409570493\n",
      "Fetched 100 rows starting at offset 111369259\n",
      "Fetched 100 rows starting at offset 448167349\n",
      "Total rows fetched: 900\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import random\n",
    "\n",
    "# Define the API endpoint and parameters\n",
    "url = \"https://datasets-server.huggingface.co/rows\"\n",
    "params = {\n",
    "    \"dataset\": \"nyu-dice-lab/wavepulse-radio-raw-transcripts\",\n",
    "    \"config\": \"default\",\n",
    "    \"split\": \"train\",\n",
    "    \"offset\": 0,\n",
    "    \"length\": 100  # Fetch 100 rows per request\n",
    "}\n",
    "\n",
    "# Function to get the total number of rows in the dataset\n",
    "def get_total_rows():\n",
    "    try:\n",
    "        # Make a request to fetch metadata about the dataset\n",
    "        response = requests.get(url, params={**params, \"offset\": 0, \"length\": 1})\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        data = response.json()\n",
    "        \n",
    "        # Check if the response contains the total number of rows\n",
    "        if \"num_rows_total\" in data:\n",
    "            return data[\"num_rows_total\"]\n",
    "        else:\n",
    "            print(\"Error: 'num_rows_total' not found in the API response.\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Initialize an empty list to store all rows\n",
    "all_rows = []\n",
    "\n",
    "# Get the total number of rows in the dataset\n",
    "total_rows = get_total_rows()\n",
    "if total_rows is None:\n",
    "    print(\"Unable to determine the total number of rows in the dataset. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Number of random rows to fetch\n",
    "num_random_rows = 1000  # Adjust this as needed\n",
    "\n",
    "# Calculate the number of requests needed\n",
    "num_requests = (num_random_rows + params[\"length\"] - 1) // params[\"length\"]\n",
    "\n",
    "# Fetch random rows in chunks of 100\n",
    "for _ in range(num_requests):\n",
    "    # Generate a random offset, ensuring it doesn't exceed the dataset's bounds\n",
    "    random_offset = random.randint(0, max(0, total_rows - params[\"length\"]))\n",
    "    params[\"offset\"] = random_offset\n",
    "    \n",
    "    # Make the GET request to the API\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch data: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "    \n",
    "    # Extract the rows from the response\n",
    "    if \"rows\" in data:\n",
    "        rows = [row['row'] for row in data['rows']]\n",
    "        all_rows.extend(rows)\n",
    "        print(f\"Fetched {len(rows)} rows starting at offset {random_offset}\")\n",
    "    else:\n",
    "        print(\"Error: 'rows' not found in the API response.\")\n",
    "        continue\n",
    "\n",
    "    # Stop if we've fetched enough rows\n",
    "    if len(all_rows) >= num_random_rows:\n",
    "        break\n",
    "\n",
    "# Trim the list if we fetched more rows than needed\n",
    "all_rows = all_rows[:num_random_rows]\n",
    "\n",
    "# Now `all_rows` contains the desired number of randomly selected rows\n",
    "print(f\"Total rows fetched: {len(all_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              transcript_id  segment_index  start_time  end_time  \\\n",
      "0  WV_WSCW_2024_11_16_01_00            410    1779.612  1781.493   \n",
      "1  WV_WSCW_2024_11_16_01_00            411    1781.713  1784.234   \n",
      "2  WV_WSCW_2024_11_16_01_00            412    1784.294  1785.214   \n",
      "3  WV_WSCW_2024_11_16_01_00            413    1785.254  1787.235   \n",
      "4  WV_WSCW_2024_11_16_01_00            414    1787.655  1793.422   \n",
      "\n",
      "                                                text station  \\\n",
      "0  No, no, the point is you can't talk to a liberal.    WSCW   \n",
      "1  You've been lying so long you don't know how t...    WSCW   \n",
      "2                                    Time to decide.    WSCW   \n",
      "3                        Donald Trump for president!    WSCW   \n",
      "4   The difference between Biden and Trump is tha...    WSCW   \n",
      "\n",
      "              datetime state     speaker  \n",
      "0  2024-11-16T01:00:00    WV  SPEAKER_02  \n",
      "1  2024-11-16T01:00:00    WV  SPEAKER_02  \n",
      "2  2024-11-16T01:00:00    WV  SPEAKER_02  \n",
      "3  2024-11-16T01:00:00    WV  SPEAKER_17  \n",
      "4  2024-11-16T01:00:00    WV  SPEAKER_17  \n",
      "Total rows in the dataset: 900\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Convert the list of rows to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_rows)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "print(f\"Total rows in the dataset: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique states in the dataset: ['WV' 'NH' 'CA' 'DC' 'PA' 'KS' 'OK' 'FL']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique states from the DataFrame\n",
    "unique_states = df['state'].unique()\n",
    "\n",
    "# Display the unique states\n",
    "print(\"Unique states in the dataset:\", unique_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been downloaded as 'random_radio_raw_transcripts.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('random_radio_raw_transcripts.csv', index=False)\n",
    "\n",
    "print(\"Dataset has been downloaded as 'random_radio_raw_transcripts.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CarterCapstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
