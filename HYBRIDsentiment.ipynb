{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a61f7a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "c:\\Users\\cassi\\anaconda3\\envs\\Capstone2\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "Analyzing transcripts: 100%|██████████| 624/624 [52:51:20<00:00, 304.94s/it]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. Results saved to: stratifiedSentimentData/stratified_radio_sample_TextBlob_HYBRID.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "\n",
    "# Initialize analyzers\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model_name,\n",
    "    return_all_scores=True\n",
    ")\n",
    "\n",
    "def analyze_sentence(sentence):\n",
    "    \"\"\"Analyze a single sentence with hybrid approach\"\"\"\n",
    "    # VADER analysis\n",
    "    vader_score = vader.polarity_scores(sentence)['compound']  # -1 to 1\n",
    "    \n",
    "    # Transformer analysis\n",
    "    try:\n",
    "        result = sentiment_analyzer(sentence)[0]\n",
    "        trans_scores = {item['label'].lower(): item['score'] for item in result}\n",
    "    except:\n",
    "        trans_scores = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "    \n",
    "    # Hybrid scoring (adjust weights as needed)\n",
    "    hybrid_scores = {\n",
    "        'positive': 0.6 * trans_scores.get('positive', 0) + 0.4 * max(0, vader_score),\n",
    "        'negative': 0.6 * trans_scores.get('negative', 0) + 0.4 * max(0, -vader_score),\n",
    "        'neutral': 0.6 * trans_scores.get('neutral', 0) + 0.4 * (1 - abs(vader_score))\n",
    "    }\n",
    "    \n",
    "    dominant = max(hybrid_scores.items(), key=lambda x: x[1])\n",
    "    return {\n",
    "        'sentence': sentence,\n",
    "        'sentiment': dominant[0],\n",
    "        'confidence': dominant[1],\n",
    "        **hybrid_scores\n",
    "    }\n",
    "\n",
    "def analyze_transcript(transcript):\n",
    "    \"\"\"Analyze a full transcript\"\"\"\n",
    "    if pd.isna(transcript) or not str(transcript).strip():\n",
    "        return {\n",
    "            'positive': 0,\n",
    "            'negative': 0,\n",
    "            'neutral': 0,\n",
    "            'avg_score': 0,\n",
    "            'sentence_count': 0\n",
    "        }\n",
    "    \n",
    "    sentences = sent_tokenize(str(transcript))\n",
    "    results = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        results.append(analyze_sentence(sentence))\n",
    "    \n",
    "    if not results:\n",
    "        return {\n",
    "            'positive': 0,\n",
    "            'negative': 0,\n",
    "            'neutral': 0,\n",
    "            'avg_score': 0,\n",
    "            'sentence_count': 0\n",
    "        }\n",
    "    \n",
    "    # Aggregate results\n",
    "    sentiment_counts = pd.DataFrame(results)['sentiment'].value_counts()\n",
    "    avg_score = np.mean([r['confidence'] if r['sentiment'] in ['positive','negative'] else 0 \n",
    "                       for r in results])\n",
    "    \n",
    "    return {\n",
    "        'positive': sentiment_counts.get('positive', 0),\n",
    "        'negative': sentiment_counts.get('negative', 0),\n",
    "        'neutral': sentiment_counts.get('neutral', 0),\n",
    "        'avg_score': avg_score,\n",
    "        'sentence_count': len(results),\n",
    "        'sentence_details': results  # Optional: store individual sentence results\n",
    "    }\n",
    "\n",
    "def analyze_dataframe(df, text_column='text'):\n",
    "    \"\"\"Analyze all transcripts in a DataFrame\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Analyzing transcripts\"):\n",
    "        transcript = row[text_column]\n",
    "        analysis = analyze_transcript(transcript)\n",
    "        results.append(analysis)\n",
    "    \n",
    "    # Create new columns\n",
    "    result_cols = pd.DataFrame(results)\n",
    "    result_cols['positive_prop'] = result_cols['positive'] / result_cols['sentence_count']\n",
    "    result_cols['negative_prop'] = result_cols['negative'] / result_cols['sentence_count']\n",
    "    result_cols['neutral_prop'] = result_cols['neutral'] / result_cols['sentence_count']\n",
    "    \n",
    "    # Merge with original data\n",
    "    return pd.concat([df.reset_index(drop=True), result_cols], axis=1)\n",
    "\n",
    "# Usage\n",
    "input_path = 'stratifiedSentimentData/stratified_radio_sample_TextBlob.csv'  # Example input path\n",
    "data = pd.read_csv(input_path)\n",
    "analyzed_data = analyze_dataframe(data)  # Automatically uses 'text' column\n",
    "\n",
    "# Save results\n",
    "output_path = input_path.replace('.csv', '_HYBRID.csv')\n",
    "analyzed_data.to_csv(output_path, index=False)\n",
    "print(f\"Analysis complete. Results saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
